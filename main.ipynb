{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from llm import load_llm\n",
    "from answer_retriever import load_qa_retriever, load_qa_kb, retrieve_qa_context\n",
    "from utils import QADataset, remove_prompt, evaluate_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "cache_dir = '/scratch/czhao93/huggingface/hub/'\n",
    "qa_kb_path='/scratch/czhao93/CyberBot/dataset/kb/'\n",
    "query_path = '/scratch/czhao93/CyberBot/dataset/qa/split/'\n",
    "save_path = '/scratch/czhao93/CyberBot/result/'\n",
    "\n",
    "batch_size = 16\n",
    "repeat = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # load retrieval model\n",
    "    qa_retriever, qa_tokenizer = load_qa_retriever(cache_dir=cache_dir)\n",
    "    kb = load_qa_kb(path=qa_kb_path)\n",
    "\n",
    "    # load llm\n",
    "    model, tokenizer = load_llm(cache_dir=cache_dir)\n",
    "\n",
    "    query_name = os.listdir(query_path)\n",
    "    for name in query_name:\n",
    "        metrics = []\n",
    "        for _ in range(repeat):\n",
    "            \n",
    "            # load queries\n",
    "            current_path = os.path.join(query_path, name)\n",
    "            df = pd.read_csv(current_path)\n",
    "            questions = df['Question']\n",
    "            answers = df['Answer']\n",
    "    \n",
    "            # retrieve context\n",
    "            prompts = retrieve_qa_context(questions.tolist(), kb, qa_retriever, qa_tokenizer, k=1)\n",
    "    \n",
    "            # load dataset\n",
    "            dataset = QADataset(prompts, answers.tolist(), tokenizer, max_len=256)\n",
    "            data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "            raw_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(data_loader):\n",
    "                    input_ids = batch['input_ids'].to(device)\n",
    "                    attention_mask = batch['attention_mask'].to(device)\n",
    "                    outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_new_tokens=256, num_beams=4)\n",
    "                    decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "                    raw_predictions.extend(decoded_preds)\n",
    "                    \n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "    \n",
    "            predictions = remove_prompt(prompts, raw_predictions)\n",
    "    \n",
    "            results = [{\"Question\": q, 'Retrieval': r, 'Answer': a, \"Prediction\": p} for q, r, a, p in zip(questions, prompts, answers, predictions)]\n",
    "            # save_name = \"rag_{0}.json\".format(name)\n",
    "            # with open(os.path.join(save_path,save_name), 'w') as f:\n",
    "            #     json.dump(results, f, indent=4)\n",
    "    \n",
    "            references = [[ref] for ref in answers]\n",
    "            bertscore_f1, meteor_score, rouge1, rouge2 = evaluate_answer(predictions, references)\n",
    "            \n",
    "            metric = [bertscore_f1, meteor_score, rouge1, rouge2]\n",
    "            metrics.append(metric)\n",
    "\n",
    "        metrics = np.array(metrics)\n",
    "        metric_path = os.path.join(save_path,'metric_{0}.npy'.format(name))\n",
    "        np.save(metric_path, metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
